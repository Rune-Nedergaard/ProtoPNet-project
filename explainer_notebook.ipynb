{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of content\n",
    "This explainer notebook contains most of the code used to produce the results in the report. \n",
    "\n",
    "The training of the model itself is found contained in ``main.py``, ``model.py``, ``settings.py``, ``preprocess.py``, ``train_and_test.py``, ``run_pruning.py`` and ``push.py``. \n",
    "\n",
    "imgcrop, split_df,\n",
    "train,\n",
    "errorcheck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import color, io, measure, img_as_ubyte\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data\n",
    "First we prepare the Caltech birds dataset. This crops the images and splits them into train/test folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = pd.read_csv(\"data/CUB_200_2011/bounding_boxes.txt\", delimiter=' ', header=  None, index_col= 0)\n",
    "images = pd.read_csv(\"data/CUB_200_2011/images.txt\", header = None, delimiter= ' ', index_col= 0 )\n",
    "img_list = images.values.tolist() #made indexing more confusing because it didn't fit boxes df\n",
    "\n",
    "\n",
    "#Split the cropped images into training and test sets, using train_test_split.txt (included in the dataset)\n",
    "test_path = \"datasets/cub200_cropped/train_cropped/\"\n",
    "train_path = \"datasets/cub200_cropped/test_cropped/\"\n",
    "crop_path = \"cropped/\"\n",
    "img_path = \"data/CUB_200_2011/images/\"\n",
    "\n",
    "#Crop the images using information from bounding_boxes.txt (included in the dataset)\n",
    "for count, file in enumerate(images.values):\n",
    "    img = io.imread(img_path+images.iloc[count].values[0])\n",
    "    x, y, width, height = boxes.iloc[count].values\n",
    "    img = img[y:y+height,x:x+width]\n",
    "    io.imsave(crop_path+str(count+1)+'.jpg', img)\n",
    "\n",
    "\n",
    "split = pd.read_csv('data/CUB_200_2011/train_test_split.txt', delimiter=' ', header  = None)\n",
    "\n",
    "def makedir(path):\n",
    "    '''\n",
    "    if path does not exist in the file system, create it\n",
    "    '''\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "#move the images into the correct folders\n",
    "for count, im in enumerate(split.values):\n",
    "    if im[1] == 0:\n",
    "        makedir(test_path+images.values[count][0].split('/')[0])\n",
    "        img_path = images.values[count][0]\n",
    "        shutil.move(crop_path+str(count+1)+\".jpg\",test_path+img_path)\n",
    "    elif im[1] == 1:\n",
    "        makedir(train_path+images.values[count][0].split('/')[0])\n",
    "        img_path = images.values[count][0]\n",
    "        shutil.move(crop_path+str(count+1)+\".jpg\",train_path+img_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now prepare the FETAL_PLANES_DB ultrasound dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/FETAL_PLANES_ZENODO/FETAL_PLANES_DB_data.csv', delimiter=';')\n",
    "#initialize empty category\n",
    "data['category'] = [0 for i in range(len(data))]\n",
    "\n",
    "#map images to category\n",
    "for i in range(len(data)):\n",
    "    overcategory = data['Plane'][i]\n",
    "    if overcategory != 'Fetal brain':\n",
    "        data['category'][i] = overcategory\n",
    "    else:\n",
    "        category = data['Brain_plane'][i]\n",
    "        data['category'][i] = category\n",
    "\n",
    "\n",
    "#Split the  images into training and test sets\n",
    "img_path = 'data/FETAL_PLANES_ZENODO/Images/'\n",
    "\n",
    "\n",
    "#moving images to train and test folders\n",
    "for i in range(len(data)):\n",
    "    #get category\n",
    "    category = data['category'][i]\n",
    "    if data['Train '][i] == 1:\n",
    "        makedir('datasets/FETAL_PLANES_DB/train/' + category)\n",
    "        source = str(img_path + data['Image_name'][i] + '.png')\n",
    "        destination = str('datasets/FETAL_PLANES_DB/train/' + category + '/' + data['Image_name'][i] + '.png')\n",
    "        shutil.copy(source, destination)\n",
    "    else:\n",
    "        makedir('datasets/FETAL_PLANES_DB/test/' + category)\n",
    "        source = str(img_path + data['Image_name'][i] + '.png')\n",
    "        destination = str('datasets/FETAL_PLANES_DB/test/' + category + '/' + data['Image_name'][i] + '.png')\n",
    "        shutil.copy(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb6f1310e4cbbe83899fa3e2dcaa83329108f92c90079e59df5f7ddb93fa3967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
